# -*- coding: utf-8 -*-
"""vgg11_scratch_cifar100_prune.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17y_Y8rdSSZIo3odl7LMsCBtwdxwc7dI-
"""

import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import torch.nn as nn
from torch.utils.data import DataLoader
import torch.nn.functional as F

from google.colab import drive
drive.mount('/content/drive')

transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))
])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

class VGG11(nn.Module):
    def __init__(self, in_channels=3, num_classes=100):
        super(VGG11, self).__init__()

        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 16x16
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 8x8
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 4x4
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 2x2
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 1x1
        )

        self.linear_layers = nn.Sequential(
            nn.Linear(512 * 1 * 1, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(4096, num_classes)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        return self.linear_layers(x)

model = VGG11().to(device)
dummy = torch.randn(2, 3, 32, 32).to(device)
print(model(dummy).shape)

model = torch.load("/content/drive/MyDrive/vgg11cifar100_scratch.pth", map_location=device, weights_only=False)
model.to(device)
model.eval()

model.eval()
print("Model loaded successfully and ready for inference!")

def evaluate_model(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total

accuracy_initial = evaluate_model(model, testloader, device)

print(accuracy_initial)

!pip install thop

import torch
from thop import profile

accuracy_dict = {}
flops_dict = {}
params_dict = {}

accuracy_dict['initial'] = accuracy_initial

with torch.cuda.device(0 if torch.cuda.is_available() else -1):
    flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).to(device),))

flops_dict['initial'] = flops
params_dict['initial'] = params

print(f"Accuracy: {accuracy_dict['initial']:.4f}%")
print(f"FLOPs: {flops_dict['initial'] / 1e6:.4f} MFLOPs")
print(f"Params: {params_dict['initial'] / 1e6:.4f} MParams")

def compute_flops(model, input_size=(1, 3, 32, 32)):
    from thop import profile
    dummy_input = torch.randn(input_size)
    flops, _ = profile(model, inputs=(dummy_input,))
    return flops

def compute_params(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def finetune_model(model, trainloader, device, epochs=3):
    model.train()
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

    for epoch in range(epochs):
        running_loss = 0.0
        for i, (inputs, labels) in enumerate(trainloader, 0):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}')

    return model

import os
model_path = "/content/drive/MyDrive/vgg11cifar100_scratch.pth"

if os.path.exists(model_path):
    print("Model file exists!")
else:
    print("Model file NOT found at the expected location.")

torch.save(model.state_dict(), "vgg11cifar100_weights.pth")

model = torch.load("/content/drive/MyDrive/vgg11cifar100_scratch.pth", map_location=device, weights_only=False)
model.to(device)
model.eval()

torch.save(model.state_dict(), "vgg11cifar100_weights.pth")

prune_ratios=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
def prune_vgg11_model(model, prune_ratio):
    keep_indices = {}
    pruned_channels = {}
    layer_counter = 0

    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            l1_norms = module.weight.abs().sum(dim=(1,2,3))
            num_keep = int(module.out_channels * (1-prune_ratio))
            keep_indices[name] = torch.argsort(l1_norms, descending=True)[:num_keep]
            pruned_channels[module.out_channels] = num_keep
            layer_counter += 1
            print(f"Conv{layer_counter}: {module.out_channels}->{num_keep} filters")

    class PrunedVGG11(nn.Module):
        def __init__(self, channel_config):
            super().__init__()
            self.conv_layers = nn.Sequential(
                nn.Conv2d(3, channel_config[64], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2,2),
                nn.Conv2d(channel_config[64], channel_config[128], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2,2),
                nn.Conv2d(channel_config[128], channel_config[256], 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(channel_config[256], channel_config[256], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2,2),
                nn.Conv2d(channel_config[256], channel_config[512], 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(channel_config[512], channel_config[512], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2,2),
                nn.Conv2d(channel_config[512], channel_config[512], 3, padding=1),
                nn.ReLU(),
                nn.Conv2d(channel_config[512], channel_config[512], 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2,2)
            )

            with torch.no_grad():
                dummy = torch.randn(1,3,32,32)
                out = self.conv_layers(dummy)
                fc_input = out.view(1,-1).shape[1]

            self.linear_layers = nn.Sequential(
                nn.Linear(fc_input, 4096),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(4096, 4096),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(4096, 100)
            )

        def forward(self, x):
            x = self.conv_layers(x)
            x = x.view(x.size(0), -1)
            x = self.linear_layers(x)
            return x

    pruned_model = PrunedVGG11(pruned_channels).to(device)

    old_convs = [m for m in model.modules() if isinstance(m, nn.Conv2d)]
    new_convs = [m for m in pruned_model.modules() if isinstance(m, nn.Conv2d)]

    prev_keep = None
    for i, (old_conv, new_conv) in enumerate(zip(old_convs, new_convs)):
        current_keep = keep_indices[list(keep_indices.keys())[i]]

        if i == 0:
            new_conv.weight.data = old_conv.weight.data[current_keep]
        else:
            new_conv.weight.data = old_conv.weight.data[current_keep][:, prev_keep]

        if old_conv.bias is not None:
            new_conv.bias.data = old_conv.bias.data[current_keep]

        prev_keep = current_keep

    with torch.no_grad():
        dummy = torch.randn(1,3,32,32).to(device)
        features = pruned_model.conv_layers(dummy)
        print(f"New classifier input size: {features.view(1,-1).shape[1]}")

    return pruned_model

def finetune_model(model, trainloader, epochs=10):
    model.train()
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)

    for epoch in range(epochs):
        running_loss = 0.0
        for i, (inputs, labels) in enumerate(trainloader):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        scheduler.step()
        print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}')
    return model

for ratio in prune_ratios:
    print(f"\n=== Pruning ratio: {ratio} ===")

    state_dict = torch.load("vgg11cifar10_weights.pth")
    filtered_state_dict = {k: v for k, v in state_dict.items()
                         if not ('.total_ops' in k or '.total_params' in k or
                                 k in ['total_ops', 'total_params'])}

    base_model = VGG11()
    base_model.load_state_dict(filtered_state_dict)
    base_model.to(device)
    base_model.eval()

    pruned_model = prune_vgg11_model(base_model, prune_ratio=ratio)
    pruned_model = finetune_model(pruned_model, trainloader, epochs=10)

    acc = evaluate_model(pruned_model, testloader, device)

    with torch.cuda.device(0 if torch.cuda.is_available() else -1):

        flops, params = profile(pruned_model, inputs=(torch.randn(1, 3, 32, 32).to(device),))

    accuracy_dict[ratio] = acc
    flops_dict[ratio] = flops
    params_dict[ratio] = params

    print(f"Accuracy: {acc:.2f}%")
    print(f"FLOPs: {flops/1e6:.2f} M")
    print(f"Params: {params/1e6:.2f} M")

import matplotlib.pyplot as plt

ratios = prune_ratios
accs = [accuracy_dict[r] for r in ratios]
flops = [flops_dict[r]/1e6 for r in ratios]      # Convert to MegaFLOPs
params = [params_dict[r]/1e6 for r in ratios]    # Convert to Million Params

plt.figure(figsize=(16, 5))

# Accuracy plot
plt.subplot(1, 3, 1)
plt.plot(ratios, accs, marker='o', color='green')
plt.title("Accuracy vs Prune Ratio")
plt.xlabel("Prune Ratio")
plt.ylabel("Accuracy (%)")
plt.grid(True)

# FLOPs plot
plt.subplot(1, 3, 2)
plt.plot(ratios, flops, marker='o', color='blue')
plt.title("FLOPs vs Prune Ratio")
plt.xlabel("Prune Ratio")
plt.ylabel("FLOPs (Millions)")
plt.grid(True)

# Params plot
plt.subplot(1, 3, 3)
plt.plot(ratios, params, marker='o', color='red')
plt.title("Parameters vs Prune Ratio")
plt.xlabel("Prune Ratio")
plt.ylabel("Params (Millions)")
plt.grid(True)

plt.tight_layout()
plt.show()

print("\n=== Accuracy Dictionary ===")
for ratio in prune_ratios:
    print(f"Prune Ratio {ratio:.1f}: Accuracy = {accuracy_dict[ratio]:.4f}%")

print("\n=== FLOPs Dictionary (in Millions) ===")
for ratio in prune_ratios:
    print(f"Prune Ratio {ratio:.1f}: FLOPs = {flops_dict[ratio]/1e6:.4f} M")

print("\n=== Parameters Dictionary (in Millions) ===")
for ratio in prune_ratios:
    print(f"Prune Ratio {ratio:.1f}: Params = {params_dict[ratio]/1e6:.4f} M")

